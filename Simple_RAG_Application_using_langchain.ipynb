{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORJ4uKK2Nti+kcYQ+UBesZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hirunikathaluwage/RAG/blob/main/Simple_RAG_Application_using_langchain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xWpbNKfTbbX3",
        "outputId": "498b7c83-f247-4cdf-e592-6b9f9f018b24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.5/19.5 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.0/120.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.6/201.6 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain -qU\n",
        "!pip install langchain-openai -qU\n",
        "!pip install langchain-chroma -qU"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import necessary libraries\n",
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "A5xnu-Azc2wK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#initialize language model"
      ],
      "metadata": {
        "id": "0La7lp3ceYXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "#initialize the ChatOpenAI model\n",
        "llm = ChatOpenAI(model_name='gpt-3.5-turbo', temperature=0)"
      ],
      "metadata": {
        "id": "AgWgxJBKeS7h"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#initialize embedding model"
      ],
      "metadata": {
        "id": "ABHOEFa_h8n8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ],
      "metadata": {
        "id": "eBlCZAjFh6KW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "a3373262",
        "outputId": "d8b8b16c-6ae0-4c18-9001-e64ebddf2056"
      },
      "source": [
        "!pip install -U langchain-community -q"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/2.5 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Create embedded documents\n"
      ],
      "metadata": {
        "id": "vxhJWkkClsnR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "documents = [\n",
        "    Document(\n",
        "        page_content=\" New app nexora 2025 has been launched.\",\n",
        "        METADATA ={\"source\" \"mobile app\"},),\n",
        "\n",
        "    Document(\n",
        "        page_content=\" New desktop app new 2025 has been launched.\",\n",
        "        METADATA ={\"source\" \"desktop app\"},),\n",
        "    Document(\n",
        "        page_content=\" The AI revolution continous to transform industries and reshape the global economy.Significant advancments in articals\",\n",
        "        METADATA ={\"source\" \"ai revolution news\"},),\n",
        "]"
      ],
      "metadata": {
        "id": "4UICPO9lloga"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "vectorstore = Chroma.from_documents(documents, embedding=embedding_model\n",
        ")"
      ],
      "metadata": {
        "id": "hBp-MyIGxnHx"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Perform similarity search"
      ],
      "metadata": {
        "id": "jnULmBK872Xa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = vectorstore.similarity_search(\"mobile app\")\n",
        "\n",
        "for results in results:\n",
        "  print(results.page_content)\n",
        "  print(results.metadata)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42EXUOjB78FJ",
        "outputId": "8e91b3ad-e37c-4f9a-cdb1-88e49fc4adcf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " New app nexora 2025 has been launched.\n",
            "{}\n",
            " New desktop app new 2025 has been launched.\n",
            "{}\n",
            " The AI revolution continous to transform industries and reshape the global economy.Significant advancments in articals\n",
            "{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = vectorstore.similarity_search(\"desktop app\")\n",
        "\n",
        "for results in results:\n",
        "  print(results.page_content)\n",
        "  print(results.metadata)\n",
        "\n",
        "print(\"\\n\")\n",
        "\n",
        "results = vectorstore.similarity_search(\"ai revolution\")\n",
        "for results in results:\n",
        "  print(results.page_content)\n",
        "  print(results.metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QVNoythM62tJ",
        "outputId": "d0ddc275-5ca6-4297-cda4-538013ec5441"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " New desktop app new 2025 has been launched.\n",
            "{}\n",
            " New app nexora 2025 has been launched.\n",
            "{}\n",
            " The AI revolution continous to transform industries and reshape the global economy.Significant advancments in articals\n",
            "{}\n",
            "\n",
            "\n",
            " The AI revolution continous to transform industries and reshape the global economy.Significant advancments in articals\n",
            "{}\n",
            " New app nexora 2025 has been launched.\n",
            "{}\n",
            " New desktop app new 2025 has been launched.\n",
            "{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Embedded query and perform similerity search by vector"
      ],
      "metadata": {
        "id": "6D8No9i97pA3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_embedding = embedding_model.embed_query(\"ai revolution\")\n",
        "query_embedding[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngMLSfBD7bNH",
        "outputId": "3841ed3a-f6dc-43be-aa96-6871dc8cbc43"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.014172401279211044,\n",
              " -0.01473250798881054,\n",
              " 0.040395587682724,\n",
              " 0.0255782138556242,\n",
              " -0.004279301501810551,\n",
              " -0.017397258430719376,\n",
              " -0.04586087167263031,\n",
              " 0.037374403327703476,\n",
              " -0.02386394701898098,\n",
              " 0.006335148122161627]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(query_embedding)  #print the length of the query embedding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dbJEPb59ubA",
        "outputId": "0bb87858-3ad0-4853-f864-035cf83c2192"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1536"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Retriver\n"
      ],
      "metadata": {
        "id": "UkJU18em9-us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create a retriever from the vector\n",
        "retriever = vectorstore.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={\"k\": 1,},\n",
        ")\n",
        "\n",
        "#perform batch retrieva using the retriever\n",
        "batch_results = retriever.batch([\"Matching Learning\"])\n",
        "for result in batch_results:\n",
        "  for doc in result:\n",
        "    print(doc.page_content)\n",
        "    print(doc.metadata)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH1C0QFKwPNO",
        "outputId": "35ae4132-4dff-4b5f-b171-f5c48af9d5d5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The AI revolution continous to transform industries and reshape the global economy.Significant advancments in articals\n",
            "{}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "#define a message template for the chatbot\n",
        "message = \"\"\"\n",
        "answer this question using the provided context only.\n",
        "\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "#Create a chat prompt template from the message\n",
        "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])"
      ],
      "metadata": {
        "id": "CO6dgxEEm3-E"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chain retriever and prompt template with LLM"
      ],
      "metadata": {
        "id": "EWOLMIElaw7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | llm"
      ],
      "metadata": {
        "id": "PiWgraBiavij"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.invoke(\"current mobile apps\")\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzetB0s4bErL",
        "outputId": "ce0d9424-2044-4040-f2f0-ecab85f4d5ae"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There is a new desktop app called new 2025 that has been launched.\n"
          ]
        }
      ]
    }
  ]
}